# AI_Hardware_Project_ECE6501_Group_4

## Team Name: 
(Enter your team name from Canvas)
- ECE6501-Group4
## Team Members:
- Jiandi Wang
- Yunwei Cai
- Zilin Wang
- Henan Zhao

## Project Title:
(Enter your project title - be creative)
- Accelerated Testing of Image Classification Task Based on Raspberry Pi 5

## Project Description:
(Provide a short description of the problem you're addressing)
- The image classification task was accelerated on Raspberry Pi with Waveshare Hailo-8 accelerators.
- Comparing different models like MobileNet and ResNet, we show efficient AI reasoning on edge devices.

## Key Objectives:
- Task Acceleration: Image classification task was accelerated on Raspberry Pi with Waveshare Hailo-8 accelerators.
- Model Comparison: Different models like MobileNet and ResNet were compared for efficient AI reasoning on edge devices.


## Technology Stack:
(List the hardware platform, software tools, language(s), etc. you plan to use)
### Hardware platform
- Raspberry Pi Start Guide
- M.2 Waveshare Hailo-8 Acce A; with PCIe To M.2 adaptor 

### Software Tools
- Raspberry Pi OS: The operating system running on the Raspberry Pi, providing a Linux-based environment for development.
- Hailo-8 SDK: Software development kit for Hailo-8, which includes libraries and tools for model conversion, optimization, and deployment on the Hailo-8 accelerator.
- TensorFlow Lite: Lightweight version of TensorFlow designed for mobile and embedded devices, used for running inference with optimized models.
- ONNX Runtime: A cross-platform, high-performance scoring engine for Open Neural Network Exchange (ONNX) models, enabling compatibility with various pre-trained models.
- Python: Main programming language for development, scripting, and model interaction.
- Visual Studio Code: For interactive testing, data analysis, and visualization of results.
- Matplotlib or Seaborn: Python libraries for data visualization, used to create graphs comparing inference time, FPS, accuracy, etc.
- psutil: Python library for monitoring CPU and memory usage during inference, used to gather resource usage statistics.

### Languages
- Python: Used for writing scripts to load models, run inference, and collect performance metrics.
  
### Data Sources
- Image Classification Datasets: Public datasets like CIFAR-10 or MNIST for model testing and benchmarking.

## Expected Outcomes:
(Describe what you expect to deliver at the end of the project)
### Compare the following metrics between different models:
- Inference time.
- Inference speed (frames per second).
- Accuracy, and CPU/memory utilization.
- The impact of quantization and optimization (if time permits).

## Timeline:
(Provide a rough timeline or milestones for the project)
- About 5/12/2024
